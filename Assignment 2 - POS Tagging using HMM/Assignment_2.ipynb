{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7PVkyFT6NhP"
   },
   "source": [
    "# Hidden Markov Models \n",
    "###  Greedy and Viterbi Decoding "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted by: Anushka Deshpande"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8p0_0Mq06Wy-"
   },
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7Nt8AFAicCw4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxE1jEWGX_Wh"
   },
   "source": [
    "## Task 1: Voccabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "w21UUHozcWcV",
    "outputId": "d9bc95ce-c6e4-4b34-86a7-08c69d132241"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912090</th>\n",
       "      <td>22</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912091</th>\n",
       "      <td>23</td>\n",
       "      <td>San</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912092</th>\n",
       "      <td>24</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912093</th>\n",
       "      <td>25</td>\n",
       "      <td>instead</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912094</th>\n",
       "      <td>26</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>912095 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index       word  tag\n",
       "0           1     Pierre  NNP\n",
       "1           2     Vinken  NNP\n",
       "2           3          ,    ,\n",
       "3           4         61   CD\n",
       "4           5      years  NNS\n",
       "...       ...        ...  ...\n",
       "912090     22         to   TO\n",
       "912091     23        San  NNP\n",
       "912092     24  Francisco  NNP\n",
       "912093     25    instead   RB\n",
       "912094     26          .    .\n",
       "\n",
       "[912095 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame\n",
    "with open(\"train\", 'r') as train:\n",
    "  dataframe = pd.read_csv(train, sep = \"\\t\", names = [\"index\", \"word\", \"tag\"])\n",
    "  train.close()\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ao6EVywxdCsG",
    "outputId": "af699151-6ca6-4457-85db-6816a1a05714"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    word  tag  occurence\n",
       "0      1  Pierre  NNP          6\n",
       "1      2  Vinken  NNP          2\n",
       "2      3       ,    ,      46476\n",
       "3      4      61   CD         25\n",
       "4      5   years  NNS       1130"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['occurence'] = dataframe.groupby('word')['word'].transform('size')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "noIPk5D8eJuZ",
    "outputId": "aa6baad6-16b0-4f60-ac00-297a5b96f7df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt; unk &gt;</td>\n",
       "      <td>NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     word  tag  occurence\n",
       "0      1   Pierre  NNP          6\n",
       "1      2  < unk >  NNP          2\n",
       "2      3        ,    ,      46476\n",
       "3      4       61   CD         25\n",
       "4      5    years  NNS       1130"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 3\n",
    "def UNKreplace(entry):\n",
    "  if entry.occurence <= threshold:\n",
    "    return \"< unk >\"\n",
    "  else:\n",
    "    return entry.word\n",
    "\n",
    "dataframe['word'] = dataframe.apply(lambda entry: UNKreplace(entry), axis = 1)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "R2Fm6uushZW3",
    "outputId": "911af962-a537-4bba-b2fd-5cc1e404b4a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; unk &gt;</td>\n",
       "      <td>42044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>39533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>37452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>22104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  occurence\n",
       "0        ,      46476\n",
       "1  < unk >      42044\n",
       "2      the      39533\n",
       "3        .      37452\n",
       "4       of      22104"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVocab = dataframe.word.value_counts().rename_axis('word').reset_index(name = 'occurence')\n",
    "dfVocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qDJaOzeGjCR4",
    "outputId": "90fa6fe3-4db8-4ec0-a3ec-4d494b6c856b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; unk &gt;</td>\n",
       "      <td>42044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  occurence\n",
       "1  < unk >      42044"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUnk = dfVocab[dfVocab['word'] == '< unk >']\n",
    "dfUnk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "7UeRIohLj8VU",
    "outputId": "d27d9ca3-620d-4353-cea9-96c408bd2fc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>39533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>37452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>22104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>21305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  occurence\n",
       "0    ,      46476\n",
       "2  the      39533\n",
       "3    .      37452\n",
       "4   of      22104\n",
       "5   to      21305"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVocab = dfVocab.drop(dfVocab[dfVocab.word == '< unk >'].index)\n",
    "dfVocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "Rr1eww6DkVwv",
    "outputId": "f6eb3c5e-c8f7-4c9a-e76d-731391135851"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>id</th>\n",
       "      <th>occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt; unk &gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>42044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "      <td>39533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>4</td>\n",
       "      <td>37452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>5</td>\n",
       "      <td>22104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  id  occurence\n",
       "0  < unk >   1      42044\n",
       "1        ,   2      46476\n",
       "2      the   3      39533\n",
       "3        .   4      37452\n",
       "4       of   5      22104"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalVocab = pd.concat([dfUnk, dfVocab]).reset_index(drop=True)\n",
    "finalVocab['id'] = finalVocab.index + 1\n",
    "columnList = finalVocab.columns.tolist()\n",
    "columnList = [columnList[0], columnList[-1], columnList[1]]\n",
    "finalVocab = finalVocab[columnList]\n",
    "finalVocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmF2jEv2_NQx"
   },
   "source": [
    "generate the vocab.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qcxBZirU2eMl"
   },
   "outputs": [],
   "source": [
    "finalVocab.to_csv('vocab.txt', sep='\\t', header=None, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcEOyvv62nci",
    "outputId": "71adee05-ca6b-4348-a358-34d711643b40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Threshold:  3\n",
      "Size of Vocabulary:  13751\n",
      "Total occurences of < unk> :  42044\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected Threshold: \" , threshold)\n",
    "print(\"Size of Vocabulary: \", finalVocab.shape[0])\n",
    "print(\"Total occurences of < unk> : \",  dfUnk['occurence'].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9g-hdcrX9ga"
   },
   "source": [
    "## Task 2: Model Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5d94Vr-9SnE"
   },
   "source": [
    "**Counting the unique tags in the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dURUEyOBC2Kk",
    "outputId": "74309832-a4e6-46a2-f663-c30122869905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique tags:  45\n"
     ]
    }
   ],
   "source": [
    "dfPos = dataframe.tag.value_counts().rename_axis('pos').reset_index(name='count')\n",
    "POSCountDict = dict(dfPos.values)\n",
    "tagList = dfPos.pos.tolist()\n",
    "print('Total Unique tags: ', len(tagList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_ZzNijf9Yh1"
   },
   "source": [
    "**Creating a mapping for the text sentence wise, maps word -> tag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzG2gicSECd5",
    "outputId": "63b6951d-a1c5-4e04-baba-5f07b601c263"
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "sentence = []\n",
    "first = 1\n",
    "for entry in dataframe.itertuples():\n",
    "    if(entry.index == 1 and first == 0):\n",
    "        text.append(sentence)\n",
    "        sentence = []\n",
    "    first = 0\n",
    "    sentence.append((entry.word, entry.tag))\n",
    "text.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KqJVGlJfESLn"
   },
   "outputs": [],
   "source": [
    "vocabulary = finalVocab.word.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOxv_GWU91aI"
   },
   "source": [
    "Now, we have the following information:\n",
    "\n",
    "1. tagList = list of tags (45)\n",
    "2. vocab = list of unique words in df\n",
    "3. sentences = each word in each sentence tagged with its POS\n",
    "4. POSCountDict = count of each POS in the df\n",
    "\n",
    "So we generate the transition matrix and emission matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CxaEyEPv90ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 45)\n"
     ]
    }
   ],
   "source": [
    "# calculate the transition matrix\n",
    "t_matrix = np.zeros((len(tagList), len(tagList)))\n",
    "tagCount = {}\n",
    "\n",
    "for tag in range(len(tagList)):\n",
    "  tagCount[tag] = 0\n",
    "\n",
    "for sent in text:\n",
    "  for i in range(len(sent)):\n",
    "    tagCount[tagList.index(sent[i][1])] += 1\n",
    "    if i == 0:\n",
    "      continue\n",
    "    t_matrix[tagList.index(sent[i-1][1])][tagList.index(sent[i][1])] += 1\n",
    "\n",
    "for i in range(len(t_matrix)):\n",
    "  for j in range(len(t_matrix[0])):\n",
    "    if t_matrix[i][j] == 0:\n",
    "      t_matrix[i][j] = 1e-10\n",
    "    else:\n",
    "      t_matrix[i][j] /= tagCount[i] \n",
    "\n",
    "#print(t_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LAM734eKVm7",
    "outputId": "aec3be89-e00a-4ebd-eae1-260c91e9405f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 13751)\n"
     ]
    }
   ],
   "source": [
    "# calculate emission matrix\n",
    "e_matrix = np.zeros((len(tagList), len(vocabulary)))\n",
    "\n",
    "for sent in text:\n",
    "  for word, tag in sent:\n",
    "    e_matrix[tagList.index(tag)][vocabulary.index(word)] += 1\n",
    "\n",
    "for i in range(len(e_matrix)):\n",
    "  for j in range(len(e_matrix[0])):\n",
    "    if e_matrix[i][j] == 0:\n",
    "      e_matrix[i][j] = 1e-10\n",
    "    else:\n",
    "      e_matrix[i][j] /= tagCount[i]\n",
    "\n",
    "#print(e_matrix.shape)\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spfQlGOJ-JrN"
   },
   "source": [
    "Now we generate a dictionary for the transition and emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_xlmydZqLfPk"
   },
   "outputs": [],
   "source": [
    "# make dictionary of transition probabilities\n",
    "\n",
    "tagsDict = {}\n",
    "for i in range(len(tagList)):\n",
    "  tagsDict[i] = tagList[i]\n",
    "\n",
    "transitionProbability = {}\n",
    "for i in range(len(t_matrix)):\n",
    "  for j in range(len(t_matrix[0])):\n",
    "    transitionProbability[\"(\" + tagsDict[i] + \",\" + tagsDict[j] + \")\"] = t_matrix[i][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KPzRysEWNWmQ"
   },
   "outputs": [],
   "source": [
    "# make dictionary of emission probabilities\n",
    "\n",
    "emissionProbability = {}\n",
    "for i in range(len(e_matrix)):\n",
    "  for j in range(len(e_matrix[0])):\n",
    "    emissionProbability[\"(\" + tagsDict[i] + \",\" + vocabulary[j] + \")\"] = e_matrix[i][j]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyprvPfM-PVr"
   },
   "source": [
    "We generate the probabilities for \\<start\\> and \\<key\\> tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KBBf3aGuUKu4"
   },
   "outputs": [],
   "source": [
    "# calculate the initial probabilities of tags\n",
    "\n",
    "tagsStartCount = {}\n",
    "startSum = 0\n",
    "for tag in tagList:\n",
    "  tagsStartCount[tag] = 0\n",
    "\n",
    "for entry in dataframe.itertuples():\n",
    "  if entry[1] == 1:\n",
    "    tagsStartCount[entry[3]] += 1\n",
    "    startSum += 1\n",
    "\n",
    "initProbability = {}\n",
    "for tag in tagsStartCount.keys():\n",
    "  initProbability[tag] = tagsStartCount[tag] / startSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFEgNNbE_AL3"
   },
   "source": [
    "Append the initial probabilities to the transition probabilities to generate the final transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aW5v9goxVope"
   },
   "outputs": [],
   "source": [
    "# append initial probabilities to transition probabilities\n",
    "\n",
    "finalTransitionProb = {}\n",
    "for tag in initProbability.keys():\n",
    "  finalTransitionProb[\"(\" + \"< start >\" + \",\" + tag + \")\"] = initProbability[tag]\n",
    "\n",
    "finalTransitionProb.update(transitionProbability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMEij4XqWNdB",
    "outputId": "13fbb0e9-be06-46c3-e100-d4e413c2ec8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transition parameters:  2070\n",
      "Total emission paramenters:   618795\n"
     ]
    }
   ],
   "source": [
    "print(\"Total transition parameters: \", str(len(finalTransitionProb)))\n",
    "print(\"Total emission paramenters:  \", str(len(emissionProbability)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fsg5XjMy_JyT"
   },
   "source": [
    "generate the hmm.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "N0CdfkOmWb2M"
   },
   "outputs": [],
   "source": [
    "# store in hmm.json file\n",
    "import json\n",
    "with open('hmm.json', 'w') as hmmFile:\n",
    "  json.dump({\"transition\" : finalTransitionProb, \"emission\" : emissionProbability}, hmmFile, ensure_ascii=False, indent = 4)\n",
    "  hmmFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWcdwNXRYBK1"
   },
   "source": [
    "## Task 3: Greedy Decoding with HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwnvaF7__Ve2"
   },
   "source": [
    "preprocess the validation dataset to generate the sentences and find the word, tag pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ec3XvVFXXHki"
   },
   "outputs": [],
   "source": [
    "# preprocess dev data aka validation set\n",
    "\n",
    "validationData = pd.read_csv(\"dev\", sep=\"\\t\", names = ['index', 'word', 'tag'])\n",
    "validationData['occurence'] = validationData.groupby('word')['word'].transform('size')\n",
    "\n",
    "validationSentences = []\n",
    "sentence = []\n",
    "first = 1\n",
    "for entry in validationData.itertuples():\n",
    "  if entry.index == 1 and first == 0:\n",
    "    validationSentences.append(sentence)\n",
    "    sentence = []\n",
    "  first = 0\n",
    "  sentence.append((entry.word, entry.tag))\n",
    "validationSentences.append(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrJqQt09_eJ9"
   },
   "source": [
    "use the greedy decoding algorithm to generate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EHQpXrrPaeYM"
   },
   "outputs": [],
   "source": [
    "# greedy decoding for validation data\n",
    "\n",
    "tagPredictions = []\n",
    "tagScores = []\n",
    "\n",
    "for sent in validationSentences:\n",
    "  previousTag = \"< start >\"\n",
    "  sentPrediction = []\n",
    "  sentScore = []\n",
    "\n",
    "  for i in range(len(sent)):\n",
    "    highestScore = -1\n",
    "    \n",
    "    for j in range(len(tagList)):\n",
    "      currScore = 1\n",
    "      if i == 0:\n",
    "        currScore *= initProbability[tagList[j]] \n",
    "      else:\n",
    "        if str(\"(\" + previousTag + \",\" + tagList[j] + \")\") in finalTransitionProb:\n",
    "          currScore *= finalTransitionProb[\"(\" + previousTag + \",\" + tagList[j] + \")\"]\n",
    "      \n",
    "      if str(\"(\" + tagList[j] + \",\" + sent[i][0] + \")\") in emissionProbability:\n",
    "        currScore *= emissionProbability[\"(\" + tagList[j] + \",\" + sent[i][0] + \")\"]\n",
    "      else:\n",
    "        currScore *= emissionProbability[\"(\" + tagList[j] + \",\" + \"< unk >\" + \")\"]\n",
    "\n",
    "      if(currScore > highestScore):\n",
    "        highestScore = currScore\n",
    "        highestProbabilityTag = tagList[j]\n",
    "    \n",
    "    previousTag = highestProbabilityTag\n",
    "    sentPrediction.append(previousTag)\n",
    "    sentScore.append(highestScore)\n",
    "  \n",
    "  tagPredictions.append(sentPrediction)\n",
    "  tagScores.append(sentScore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_7iL1Z__h21"
   },
   "source": [
    "now calculate the accuracy on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXfdP4bCfvL0",
    "outputId": "4d9e8ca9-ea57-47f3-9dc7-b71d0d7f8770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation set: 92.64 %\n"
     ]
    }
   ],
   "source": [
    "# to calculate accuracy of predictions on validation set\n",
    "\n",
    "totalPredictions = 0\n",
    "correctTagPrediction = 0\n",
    "for i in range(len(validationSentences)):\n",
    "  for j in range(len(validationSentences[i])):\n",
    "    if tagPredictions[i][j] == validationSentences[i][j][1]:\n",
    "      correctTagPrediction += 1\n",
    "    totalPredictions += 1\n",
    "\n",
    "validationAccuracy = correctTagPrediction / totalPredictions\n",
    "\n",
    "print(\"Accuracy on Validation set: {:.2f} %\".format(validationAccuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJPP7P1U_mUO"
   },
   "source": [
    "Now apply the same thing for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Q_PErrJVkRjo"
   },
   "outputs": [],
   "source": [
    "# preprocess test data set\n",
    "\n",
    "testData = pd.read_csv(\"test\", sep=\"\\t\", names = ['index', 'word', 'tag'])\n",
    "testData['occurence'] = testData.groupby('word')['word'].transform('size')\n",
    "\n",
    "testSentences = []\n",
    "sentence = []\n",
    "first = 1\n",
    "for entry in testData.itertuples():\n",
    "  if entry.index == 1 and first == 0:\n",
    "    testSentences.append(sentence)\n",
    "    sentence = []\n",
    "  first = 0\n",
    "  sentence.append(entry.word)\n",
    "testSentences.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "HBZQpSwonZvE"
   },
   "outputs": [],
   "source": [
    "# greedy decoding for test data\n",
    "\n",
    "testPredictions = []\n",
    "testScores = []\n",
    "\n",
    "for sent in testSentences:\n",
    "  previousTag = \"< start >\"\n",
    "  sentPrediction = []\n",
    "  sentScore = []\n",
    "\n",
    "  for i in range(len(sent)):\n",
    "    highestScore = -1\n",
    "    \n",
    "    for j in range(len(tagList)):\n",
    "      currScore = 1\n",
    "      if i == 0:\n",
    "        currScore *= initProbability[tagList[j]] \n",
    "      else:\n",
    "        if str(\"(\" + previousTag + \",\" + tagList[j] + \")\") in finalTransitionProb:\n",
    "          currScore *= finalTransitionProb[\"(\" + previousTag + \",\" + tagList[j] + \")\"]\n",
    "      \n",
    "      if str(\"(\" + tagList[j] + \",\" + sent[i][0] + \")\") in emissionProbability:\n",
    "        currScore *= emissionProbability[\"(\" + tagList[j] + \",\" + sent[i][0] + \")\"]\n",
    "      else:\n",
    "        currScore *= emissionProbability[\"(\" + tagList[j] + \",\" + \"< unk >\" + \")\"]\n",
    "\n",
    "      if(currScore > highestScore):\n",
    "        highestScore = currScore\n",
    "        highestProbabilityTag = tagList[j]\n",
    "    \n",
    "    previousTag = highestProbabilityTag\n",
    "    sentPrediction.append(previousTag)\n",
    "    sentScore.append(highestScore)\n",
    "  \n",
    "  testPredictions.append(sentPrediction)\n",
    "  testScores.append(sentScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AVwGVBsgn3R4"
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(testSentences)):\n",
    "  entry = []\n",
    "  for j in range(len(testSentences[i])):\n",
    "    entry.append((str(j+1), testSentences[i][j], testPredictions[i][j]))\n",
    "  result.append(entry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoOIfbYV_8am"
   },
   "source": [
    "Store the output on test data into a file (greedy.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iiu0OA9DqvUb"
   },
   "outputs": [],
   "source": [
    "with open('greedy.out', 'w') as greedyOutput:\n",
    "  for elem in result:\n",
    "    greedyOutput.write(\"\\n\".join([str(item[0]) + \"\\t\" + item[1] + \"\\t\" + item[2] for item in elem]))\n",
    "    greedyOutput.write(\"\\n\\n\")\n",
    "  greedyOutput.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdOocs3Rr4Ea"
   },
   "source": [
    "## Task 4: Viterbi decoding with HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3tevwWDAKUz"
   },
   "source": [
    "use viterbi decoding algorithm to generate the cache and viterbi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NJGLFgVirrhf"
   },
   "outputs": [],
   "source": [
    "# use viterbi decoding algorithm to generate the cache and viterbi_matrix\n",
    "\n",
    "c = []\n",
    "v = []\n",
    "\n",
    "for sent in validationSentences:\n",
    "  n = len(tagList)\n",
    "  viterbiList = []\n",
    "  cache = {}\n",
    "\n",
    "  for tag in tagList:\n",
    "    if str('(' + tag + ',' + sent[0][0] + ')') in emissionProbability:\n",
    "      viterbiList.append(initProbability[tag] * emissionProbability['(' + tag + ',' + sent[0][0] + ')'])\n",
    "    else:\n",
    "      viterbiList.append(initProbability[tag] * emissionProbability['(' + tag + ',' + '< unk >' + ')'])\n",
    "\n",
    "  for i, l in enumerate(sent):\n",
    "    word = l[0] \n",
    "    if i == 0:\n",
    "      continue\n",
    "    tempList = [None] * n\n",
    "    for j, tag in enumerate(tagList):\n",
    "      score = -1\n",
    "      value = 1\n",
    "      for k, prob in enumerate(viterbiList):\n",
    "        if str(\"(\" + tagList[k] + \",\" + tag + \")\") in transitionProbability and str(\"(\" + tag + \",\" + word + \")\") in emissionProbability:\n",
    "          value = prob * transitionProbability[\"(\" + tagList[k] + \",\" + tag + \")\"] * emissionProbability[\"(\" + tag + \",\" + word + \")\"]\n",
    "        else:\n",
    "          value = prob * transitionProbability[\"(\" + tagList[k] + \",\" + tag + \")\"] * emissionProbability[\"(\" + tag + \",\" + \"< unk >\" + \")\"]\n",
    "        \n",
    "        if(score < value):\n",
    "          score = value\n",
    "          cache[str(i) + \", \" + tag] = [tagList[k], value]\n",
    "      tempList[j] = score\n",
    "    viterbiList = [x for x in tempList]\n",
    "  \n",
    "  c.append(cache)\n",
    "  v.append(viterbiList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLc22vWaASwX"
   },
   "source": [
    "Backtrack through the matrix to fing the POS tag predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3aIaJdFSudKm"
   },
   "outputs": [],
   "source": [
    "# backtrack through matrix for pos tags\n",
    "\n",
    "VitValidationPred = []\n",
    "VitValidationScore = []\n",
    "\n",
    "for cache, viterbiList in zip(c, v):\n",
    "  numStates = len(tagList)\n",
    "  n = len(cache) // numStates\n",
    "\n",
    "  bestSequence = []\n",
    "  bestSequenceBreakdown = []\n",
    "\n",
    "  x = tagList[np.argmax(np.asarray(viterbiList))]\n",
    "  bestSequence.append(x)\n",
    "\n",
    "  for i in range(n, 0, -1):\n",
    "    val = cache[str(i) + ', ' + x][1]\n",
    "    x = cache[str(i) + ', ' + x][0]\n",
    "    bestSequence = [x] + bestSequence\n",
    "    bestSequenceBreakdown = [val] + bestSequenceBreakdown\n",
    "  \n",
    "  VitValidationPred.append(bestSequence)\n",
    "  VitValidationScore.append(bestSequenceBreakdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW8IycV6AXpu"
   },
   "source": [
    "Calculate and print the accuracy on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdRbvQjZ0S9L",
    "outputId": "d28b1c54-8bb4-462a-cfe7-8b6a3e88cd12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation set: 94.07\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy for validation set\n",
    "\n",
    "totPredictions = 0\n",
    "correctPredictions = 0\n",
    "for i in range(len(validationSentences)):\n",
    "  for j in range(len(validationSentences[i])):\n",
    "    if VitValidationPred[i][j] == validationSentences[i][j][1]:\n",
    "      correctPredictions += 1\n",
    "    totPredictions += 1\n",
    "\n",
    "valAccuracy = correctPredictions / totPredictions\n",
    "\n",
    "print(\"Accuracy on Validation set: {:.2f}\".format(valAccuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "S0s9BJn-09RS"
   },
   "outputs": [],
   "source": [
    "# follow the same process for test set\n",
    "\n",
    "c = []\n",
    "v = []\n",
    "\n",
    "for sent in testSentences:\n",
    "  n = len(tagList)\n",
    "  viterbiList = []\n",
    "  cache = {}\n",
    "\n",
    "  for tag in tagList:\n",
    "    if str('(' + tag + ',' + sent[0][0] + ')') in emissionProbability:\n",
    "      viterbiList.append(initProbability[tag] * emissionProbability['(' + tag + ',' + sent[0][0] + ')'])\n",
    "    else:\n",
    "      viterbiList.append(initProbability[tag] * emissionProbability['(' + tag + ',' + '< unk >' + ')'])\n",
    "\n",
    "  for i, l in enumerate(sent):\n",
    "    word = l[0] \n",
    "    if i == 0:\n",
    "      continue\n",
    "    tempList = [None] * n\n",
    "    for j, tag in enumerate(tagList):\n",
    "      score = -1\n",
    "      value = 1\n",
    "      for k, prob in enumerate(viterbiList):\n",
    "        if str(\"(\" + tagList[k] + \",\" + tag + \")\") in transitionProbability and str(\"(\" + tag + \",\" + word + \")\") in emissionProbability:\n",
    "          value = prob * transitionProbability[\"(\" + tagList[k] + \",\" + tag + \")\"] * emissionProbability[\"(\" + tag + \",\" + word + \")\"]\n",
    "        else:\n",
    "          value = prob * transitionProbability[\"(\" + tagList[k] + \",\" + tag + \")\"] * emissionProbability[\"(\" + tag + \",\" + \"< unk >\" + \")\"]\n",
    "        \n",
    "        if(score < value):\n",
    "          score = value\n",
    "          cache[str(i) + \", \" + tag] = [tagList[k], value]\n",
    "      tempList[j] = score\n",
    "    viterbiList = [x for x in tempList]\n",
    "  \n",
    "  c.append(cache)\n",
    "  v.append(viterbiList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "v_ujqXvk2upp"
   },
   "outputs": [],
   "source": [
    "# backtrack through matrix for pos tags\n",
    "\n",
    "VitTestPred = []\n",
    "VitTestScore = []\n",
    "\n",
    "for cache, viterbiList in zip(c, v):\n",
    "  numStates = len(tagList)\n",
    "  n = len(cache) // numStates\n",
    "\n",
    "  bestSequence = []\n",
    "  bestSequenceBreakdown = []\n",
    "\n",
    "  x = tagList[np.argmax(np.asarray(viterbiList))]\n",
    "  bestSequence.append(x)\n",
    "\n",
    "  for i in range(n, 0, -1):\n",
    "    val = cache[str(i) + ', ' + x][1]\n",
    "    x = cache[str(i) + ', ' + x][0]\n",
    "    bestSequence = [x] + bestSequence\n",
    "    bestSequenceBreakdown = [val] + bestSequenceBreakdown\n",
    "  \n",
    "  VitTestPred.append(bestSequence)\n",
    "  VitTestScore.append(bestSequenceBreakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ssrdMSdy5Yq7"
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(testSentences)):\n",
    "  entry = []\n",
    "  for j in range(len(testSentences[i])):\n",
    "    entry.append((str(j+1), testSentences[i][j], VitTestPred[i][j]))\n",
    "  result.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7KLyegxAn4D"
   },
   "source": [
    "Write the output of test data to a file (viterbi.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6t1LFQGD5mD8"
   },
   "outputs": [],
   "source": [
    "with open('viterbi.out', 'w') as greedyOutput:\n",
    "  for elem in result:\n",
    "    greedyOutput.write(\"\\n\".join([str(item[0]) + \"\\t\" + item[1] + \"\\t\" + item[2] for item in elem]))\n",
    "    greedyOutput.write(\"\\n\\n\")\n",
    "  greedyOutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
