{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI544 - Assignment 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Anushka Deshpande "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following versions of each package are used:\n",
    "\n",
    "Python 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:24:27) [Clang 14.0.6 ] \\\n",
    "Pandas 1.5.3 \\\n",
    "Numpy  1.24.2 \\\n",
    "Scikit-learn 1.2.1 \\\n",
    "NLTK  3.8.1 \\\n",
    "Tensorflow 2.11.0 \\\n",
    "Gensim  4.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdZ9-Od6uPQL",
    "outputId": "9c2aa9af-a813-460b-aa87-fdbec45df449"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:11:37.670301: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIauZ0AMyvzB",
    "outputId": "863f5e31-c1c0-4729-9884-1612221157b4"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/anushkadeshpande/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/anushkadeshpande/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/anushkadeshpande/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wEd4xTeBI3y"
   },
   "source": [
    "## 1. Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset\n",
    "\n",
    "We read the dataset using pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "id": "zgdPzkjby0w2",
    "outputId": "7b491ba1-8349-44ac-a2cc-6ca17d618bc9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>1797882</td>\n",
       "      <td>R3I2DHQBR577SS</td>\n",
       "      <td>B001ANOOOE</td>\n",
       "      <td>2102612</td>\n",
       "      <td>The Naked Bee Vitmin C Moisturizing Sunscreen ...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love this, excellent sun block!!</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>18381298</td>\n",
       "      <td>R1QNE9NQFJC2Y4</td>\n",
       "      <td>B0016J22EQ</td>\n",
       "      <td>106393691</td>\n",
       "      <td>Alba Botanica Sunless Tanning Lotion, 4 Ounce</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Thank you Alba Bontanica!</td>\n",
       "      <td>The great thing about this cream is that it do...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>19242472</td>\n",
       "      <td>R3LIDG2Q4LJBAO</td>\n",
       "      <td>B00HU6UQAG</td>\n",
       "      <td>375449471</td>\n",
       "      <td>Elysee Infusion Skin Therapy Elixir, 2oz.</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great Product, I'm 65 years old and this is al...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>19551372</td>\n",
       "      <td>R3KSZHPAEVPEAL</td>\n",
       "      <td>B002HWS7RM</td>\n",
       "      <td>255651889</td>\n",
       "      <td>Diane D722 Color, Perm And Conditioner Process...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>GOOD DEAL!</td>\n",
       "      <td>I use them as shower caps &amp; conditioning caps....</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>14802407</td>\n",
       "      <td>RAI2OIG50KZ43</td>\n",
       "      <td>B00SM99KWU</td>\n",
       "      <td>116158747</td>\n",
       "      <td>Biore UV Aqua Rich Watery Essence SPF50+/PA+++...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>this soaks in quick and provides a nice base f...</td>\n",
       "      <td>This is my go-to daily sunblock. It leaves no ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US      1797882  R3I2DHQBR577SS  B001ANOOOE         2102612   \n",
       "1          US     18381298  R1QNE9NQFJC2Y4  B0016J22EQ       106393691   \n",
       "2          US     19242472  R3LIDG2Q4LJBAO  B00HU6UQAG       375449471   \n",
       "3          US     19551372  R3KSZHPAEVPEAL  B002HWS7RM       255651889   \n",
       "4          US     14802407   RAI2OIG50KZ43  B00SM99KWU       116158747   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  The Naked Bee Vitmin C Moisturizing Sunscreen ...           Beauty   \n",
       "1      Alba Botanica Sunless Tanning Lotion, 4 Ounce           Beauty   \n",
       "2          Elysee Infusion Skin Therapy Elixir, 2oz.           Beauty   \n",
       "3  Diane D722 Color, Perm And Conditioner Process...           Beauty   \n",
       "4  Biore UV Aqua Rich Watery Essence SPF50+/PA+++...           Beauty   \n",
       "\n",
       "  star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0           5            0.0          0.0    N                 Y   \n",
       "1           5            0.0          0.0    N                 Y   \n",
       "2           5            0.0          0.0    N                 Y   \n",
       "3           5            0.0          0.0    N                 Y   \n",
       "4           5            0.0          0.0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                         Five Stars   \n",
       "1                          Thank you Alba Bontanica!   \n",
       "2                                         Five Stars   \n",
       "3                                         GOOD DEAL!   \n",
       "4  this soaks in quick and provides a nice base f...   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                   Love this, excellent sun block!!  2015-08-31  \n",
       "1  The great thing about this cream is that it do...  2015-08-31  \n",
       "2  Great Product, I'm 65 years old and this is al...  2015-08-31  \n",
       "3  I use them as shower caps & conditioning caps....  2015-08-31  \n",
       "4  This is my go-to daily sunblock. It leaves no ...  2015-08-31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"data.tsv\"\n",
    "sdf = pd.read_csv(url, sep=\"\\t\", on_bad_lines='skip')\n",
    "sdf.head() # shows first 5 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we filter for required columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iTr7GK_Ry3rA",
    "outputId": "d94d15eb-33b4-4440-bda8-ff0813b7d648"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Love this, excellent sun block!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>The great thing about this cream is that it do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great Product, I'm 65 years old and this is al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>I use them as shower caps &amp; conditioning caps....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>This is my go-to daily sunblock. It leaves no ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  star_rating                                        review_body\n",
       "0           5                   Love this, excellent sun block!!\n",
       "1           5  The great thing about this cream is that it do...\n",
       "2           5  Great Product, I'm 65 years old and this is al...\n",
       "3           5  I use them as shower caps & conditioning caps....\n",
       "4           5  This is my go-to daily sunblock. It leaves no ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = sdf[['star_rating', 'review_body']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter out 20000 reviews from each of the 3 categories and combine them to form a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eoqhShsoz1mz",
    "outputId": "cc9e96c8-15f3-4200-fb89-89187f381faa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4735045</th>\n",
       "      <td>1</td>\n",
       "      <td>Product did absolutely nothing. No results, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576764</th>\n",
       "      <td>1</td>\n",
       "      <td>I purchased the suave 30day keratin smoothing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688592</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not that I hate it - I just can't use it....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931292</th>\n",
       "      <td>1</td>\n",
       "      <td>When I received the Razorba the first thing I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690743</th>\n",
       "      <td>1</td>\n",
       "      <td>I bought it in place of the obagi elastiderm e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "4735045            1  Product did absolutely nothing. No results, no...\n",
       "4576764            1  I purchased the suave 30day keratin smoothing ...\n",
       "3688592            1  It's not that I hate it - I just can't use it....\n",
       "4931292            1  When I received the Razorba the first thing I ...\n",
       "3690743            1  I bought it in place of the obagi elastiderm e..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = new_df.query(\"star_rating == 1 | star_rating == 2\").sample(n=20000, random_state = 2)\n",
    "df_1['star_rating'] = 1\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "YGs5C8VHz5uN",
    "outputId": "8907c0e2-6e05-4734-eb76-cb7b47f47e2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3063047</th>\n",
       "      <td>2</td>\n",
       "      <td>I did something I've never done in the past --...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482781</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a nice silky and  shiny wig that's goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385503</th>\n",
       "      <td>2</td>\n",
       "      <td>Got exposed to this soap during a trip to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317014</th>\n",
       "      <td>2</td>\n",
       "      <td>Didn't realize you're supposed to use the file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072769</th>\n",
       "      <td>2</td>\n",
       "      <td>I hate polishing my nails, because at least on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3063047            2  I did something I've never done in the past --...\n",
       "3482781            2  This is a nice silky and  shiny wig that's goo...\n",
       "385503             2  Got exposed to this soap during a trip to the ...\n",
       "2317014            2  Didn't realize you're supposed to use the file...\n",
       "5072769            2  I hate polishing my nails, because at least on..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = new_df.query(\"star_rating == 3\").sample(n=20000, random_state = 2)\n",
    "df_2['star_rating'] = 2\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dUrIFn_wz8Q_",
    "outputId": "0b94d0d2-ee96-4136-b92b-9f2c3d0ebbf6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4901168</th>\n",
       "      <td>3</td>\n",
       "      <td>The product is wonderful but I'm not sure the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983887</th>\n",
       "      <td>3</td>\n",
       "      <td>Have had several shavers including Remington a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4349368</th>\n",
       "      <td>3</td>\n",
       "      <td>The illuminted side is fantastic.  As we get o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879398</th>\n",
       "      <td>3</td>\n",
       "      <td>I hate that Loreal stopped making this product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268806</th>\n",
       "      <td>3</td>\n",
       "      <td>Smells great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "4901168            3  The product is wonderful but I'm not sure the ...\n",
       "4983887            3  Have had several shavers including Remington a...\n",
       "4349368            3  The illuminted side is fantastic.  As we get o...\n",
       "2879398            3  I hate that Loreal stopped making this product...\n",
       "1268806            3                                       Smells great"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = new_df.query(\"star_rating == 4 | star_rating == 5\").sample(n=20000, random_state = 2)\n",
    "df_3['star_rating'] = 3\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-sMnRjDJz-_S",
    "outputId": "ad37826b-f2a7-4091-c081-6dc8d092fe02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083304</th>\n",
       "      <td>1</td>\n",
       "      <td>Product is so cheaply made...wasted $$$  Worst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774319</th>\n",
       "      <td>1</td>\n",
       "      <td>works ok to start out with, but start shopping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959701</th>\n",
       "      <td>1</td>\n",
       "      <td>Used this oil, didn't work, still have the toe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840155</th>\n",
       "      <td>2</td>\n",
       "      <td>It hides cleavage, but looks like a clip.  Wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014932</th>\n",
       "      <td>3</td>\n",
       "      <td>I used Hawaiian Tropic Ozone Sunblock SPF70 in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3083304            1  Product is so cheaply made...wasted $$$  Worst...\n",
       "2774319            1  works ok to start out with, but start shopping...\n",
       "4959701            1  Used this oil, didn't work, still have the toe...\n",
       "3840155            2  It hides cleavage, but looks like a clip.  Wou...\n",
       "5014932            3  I used Hawaiian Tropic Ozone Sunblock SPF70 in..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [df_1, df_2, df_3]\n",
    "final_df = pd.concat(dfs)\n",
    "\n",
    "df = shuffle(final_df, random_state = 2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "p0N_iNUV_UZE",
    "outputId": "62f7a9c5-7634-4e97-fe7b-98ef6d6082e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083304</th>\n",
       "      <td>1</td>\n",
       "      <td>Product is so cheaply made...wasted $$$  Worst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774319</th>\n",
       "      <td>1</td>\n",
       "      <td>works ok to start out with, but start shopping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959701</th>\n",
       "      <td>1</td>\n",
       "      <td>Used this oil, didn't work, still have the toe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840155</th>\n",
       "      <td>2</td>\n",
       "      <td>It hides cleavage, but looks like a clip.  Wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014932</th>\n",
       "      <td>3</td>\n",
       "      <td>I used Hawaiian Tropic Ozone Sunblock SPF70 in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3083304            1  Product is so cheaply made...wasted $$$  Worst...\n",
       "2774319            1  works ok to start out with, but start shopping...\n",
       "4959701            1  Used this oil, didn't work, still have the toe...\n",
       "3840155            2  It hides cleavage, but looks like a clip.  Wou...\n",
       "5014932            3  I used Hawaiian Tropic Ozone Sunblock SPF70 in..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['star_rating'] = df['star_rating'].astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WuV5npke_Wo-",
    "outputId": "a99a0eb5-8431-4646-a701-085b6e376ad3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating     int64\n",
       "review_body    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle null values in the dataframe by replacing null with a blank string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAbeLWiE_h8d",
    "outputId": "74944d3f-9d37-4bb8-ff96-321787d11417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star_rating - 0\n",
      "review_body - 7\n"
     ]
    }
   ],
   "source": [
    "for column in ['star_rating', 'review_body']:\n",
    "  print(column + \" - \"  + str(df[column].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Data Cleaning\n",
    "\n",
    "We perform the following actions on the dataframe: \\\n",
    "1. Convert to lowercase\n",
    "2. Remove html and url \n",
    "3. Remove non-alphabetic characters\n",
    "4. Remove extra spaces\n",
    "5. Replace contractions with their original words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VQhmPhxs_j4s",
    "outputId": "a0eb4f02-617d-42f6-c5da-40fec4111140"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083304</th>\n",
       "      <td>1</td>\n",
       "      <td>product is so cheaply made...wasted $$$  worst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774319</th>\n",
       "      <td>1</td>\n",
       "      <td>works ok to start out with, but start shopping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959701</th>\n",
       "      <td>1</td>\n",
       "      <td>used this oil, didn't work, still have the toe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840155</th>\n",
       "      <td>2</td>\n",
       "      <td>it hides cleavage, but looks like a clip.  wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014932</th>\n",
       "      <td>3</td>\n",
       "      <td>i used hawaiian tropic ozone sunblock spf70 in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3083304            1  product is so cheaply made...wasted $$$  worst...\n",
       "2774319            1  works ok to start out with, but start shopping...\n",
       "4959701            1  used this oil, didn't work, still have the toe...\n",
       "3840155            2  it hides cleavage, but looks like a clip.  wou...\n",
       "5014932            3  i used hawaiian tropic ozone sunblock spf70 in..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to lowercase\n",
    "df = df.fillna(\"\")\n",
    "df['review_body'] = df['review_body'].apply(str.lower)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "wujuK522_p-0",
    "outputId": "992221df-633b-4171-b0fe-2072620a1910"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083304</th>\n",
       "      <td>1</td>\n",
       "      <td>product is so cheaply made...wasted $$$  worst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774319</th>\n",
       "      <td>1</td>\n",
       "      <td>works ok to start out with, but start shopping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959701</th>\n",
       "      <td>1</td>\n",
       "      <td>used this oil, didn't work, still have the toe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840155</th>\n",
       "      <td>2</td>\n",
       "      <td>it hides cleavage, but looks like a clip.  wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014932</th>\n",
       "      <td>3</td>\n",
       "      <td>i used hawaiian tropic ozone sunblock spf70 in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3083304            1  product is so cheaply made...wasted $$$  worst...\n",
       "2774319            1  works ok to start out with, but start shopping...\n",
       "4959701            1  used this oil, didn't work, still have the toe...\n",
       "3840155            2  it hides cleavage, but looks like a clip.  wou...\n",
       "5014932            3  i used hawaiian tropic ozone sunblock spf70 in..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove html and urls\n",
    "def html_url(x):\n",
    "  x = re.sub('http\\S+|www.\\S+', '', x)\n",
    "  x = re.sub('<.*?>','',x)\n",
    "  return x\n",
    "\n",
    "df['review_body'] = [html_url(x) for x in df['review_body']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xzOPxH9e_uwa",
    "outputId": "9f7b2631-ae5d-4021-c758-fc0b4c4c5f3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083304</th>\n",
       "      <td>1</td>\n",
       "      <td>product is so cheaply madewasted   worst produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774319</th>\n",
       "      <td>1</td>\n",
       "      <td>works ok to start out with but start shopping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959701</th>\n",
       "      <td>1</td>\n",
       "      <td>used this oil didnt work still have the toenai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840155</th>\n",
       "      <td>2</td>\n",
       "      <td>it hides cleavage but looks like a clip  would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014932</th>\n",
       "      <td>3</td>\n",
       "      <td>i used hawaiian tropic ozone sunblock spf in m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3083304            1  product is so cheaply madewasted   worst produ...\n",
       "2774319            1  works ok to start out with but start shopping ...\n",
       "4959701            1  used this oil didnt work still have the toenai...\n",
       "3840155            2  it hides cleavage but looks like a clip  would...\n",
       "5014932            3  i used hawaiian tropic ozone sunblock spf in m..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove non-alphabetic\n",
    "def alpha(x):\n",
    "  return re.sub(r'[^a-zA-Z\\s]+', '', str(x))\n",
    "\n",
    "df['review_body'] = [alpha(x) for x in df['review_body']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NZWmmU9X_xgv",
    "outputId": "6ca753d8-68b2-41eb-c81f-c5f081b972b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083304</th>\n",
       "      <td>1</td>\n",
       "      <td>product is so cheaply madewasted worst product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774319</th>\n",
       "      <td>1</td>\n",
       "      <td>works ok to start out with but start shopping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959701</th>\n",
       "      <td>1</td>\n",
       "      <td>used this oil didnt work still have the toenai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840155</th>\n",
       "      <td>2</td>\n",
       "      <td>it hides cleavage but looks like a clip would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014932</th>\n",
       "      <td>3</td>\n",
       "      <td>i used hawaiian tropic ozone sunblock spf in m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3083304            1  product is so cheaply madewasted worst product...\n",
       "2774319            1  works ok to start out with but start shopping ...\n",
       "4959701            1  used this oil didnt work still have the toenai...\n",
       "3840155            2  it hides cleavage but looks like a clip would ...\n",
       "5014932            3  i used hawaiian tropic ozone sunblock spf in m..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spaces(x):\n",
    "  result = \" \".join(x.split())\n",
    "  return result\n",
    "\n",
    "df['review_body'] = [spaces(x) for x in df['review_body']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qD3CYb75AWPt",
    "outputId": "17aded82-6d3e-4f75-af97-f05126dca615"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083304</th>\n",
       "      <td>1</td>\n",
       "      <td>product is so cheaply madewasted worst product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774319</th>\n",
       "      <td>1</td>\n",
       "      <td>works ok to start out with but start shopping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959701</th>\n",
       "      <td>1</td>\n",
       "      <td>used this oil didnt work still have the toenai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840155</th>\n",
       "      <td>2</td>\n",
       "      <td>it hides cleavage but looks like a clip would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014932</th>\n",
       "      <td>3</td>\n",
       "      <td>i used hawaiian tropic ozone sunblock spf in m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3083304            1  product is so cheaply madewasted worst product...\n",
       "2774319            1  works ok to start out with but start shopping ...\n",
       "4959701            1  used this oil didnt work still have the toenai...\n",
       "3840155            2  it hides cleavage but looks like a clip would ...\n",
       "5014932            3  i used hawaiian tropic ozone sunblock spf in m..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4pfpa4Z20Xo",
    "outputId": "51b0ff10-2776-4f84-f7ed-7d3bd3fd8b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /Users/anushkadeshpande/opt/anaconda3/envs/testenv/lib/python3.10/site-packages (0.1.73)\r\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/anushkadeshpande/opt/anaconda3/envs/testenv/lib/python3.10/site-packages (from contractions) (0.0.24)\r\n",
      "Requirement already satisfied: anyascii in /Users/anushkadeshpande/opt/anaconda3/envs/testenv/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\r\n",
      "Requirement already satisfied: pyahocorasick in /Users/anushkadeshpande/opt/anaconda3/envs/testenv/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9o4J6mgI20-x",
    "outputId": "d5d992cb-b86f-49eb-9a8f-9b7bf6444613"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083304</th>\n",
       "      <td>1</td>\n",
       "      <td>product is so cheaply madewasted worst product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774319</th>\n",
       "      <td>1</td>\n",
       "      <td>works ok to start out with but start shopping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959701</th>\n",
       "      <td>1</td>\n",
       "      <td>used this oil did not work still have the toen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840155</th>\n",
       "      <td>2</td>\n",
       "      <td>it hides cleavage but looks like a clip would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014932</th>\n",
       "      <td>3</td>\n",
       "      <td>i used hawaiian tropic ozone sunblock spf in m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3083304            1  product is so cheaply madewasted worst product...\n",
       "2774319            1  works ok to start out with but start shopping ...\n",
       "4959701            1  used this oil did not work still have the toen...\n",
       "3840155            2  it hides cleavage but looks like a clip would ...\n",
       "5014932            3  i used hawaiian tropic ozone sunblock spf in m..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contractions\n",
    "def con(x):\n",
    "  return contractions.fix(x)\n",
    "\n",
    "df['review_body'] = [con(x) for x in df['review_body']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Data Preprocessing\n",
    "\n",
    "Use WordNetLemmatizer to lemmatize all words in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NStnRwyY3BD0",
    "outputId": "a984986e-5703-4598-fb80-5f3f53d57f2d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083304</th>\n",
       "      <td>1</td>\n",
       "      <td>product is so cheaply madewasted worst product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774319</th>\n",
       "      <td>1</td>\n",
       "      <td>work ok to start out with but start shopping f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959701</th>\n",
       "      <td>1</td>\n",
       "      <td>used this oil did not work still have the toen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840155</th>\n",
       "      <td>2</td>\n",
       "      <td>it hide cleavage but look like a clip would be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014932</th>\n",
       "      <td>3</td>\n",
       "      <td>i used hawaiian tropic ozone sunblock spf in m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "3083304            1  product is so cheaply madewasted worst product...\n",
       "2774319            1  work ok to start out with but start shopping f...\n",
       "4959701            1  used this oil did not work still have the toen...\n",
       "3840155            2  it hide cleavage but look like a clip would be...\n",
       "5014932            3  i used hawaiian tropic ozone sunblock spf in m..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemm(x):\n",
    "  return \" \".join([lemmatizer.lemmatize(word) for word in x.split()])\n",
    "\n",
    "df['review_body'] = [lemm(x) for x in df['review_body']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SZH23fMBQTd"
   },
   "source": [
    "## 2. Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrDuulmvSnPk"
   },
   "source": [
    "<b> Load the pretrained model by google 'word2vec-google-news-300' and explore it by calculating word similarities. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msKZgBIMAo_U",
    "outputId": "e8e9eddb-8a6f-4dc6-f237-d37dc05f0ee6"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as gensim\n",
    "word2vec = gensim.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Compare semantic similarities of 3 examples </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOP7nyczTho3",
    "outputId": "612c19df-4b4b-4f68-953c-8fbae28268e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( computer, technology ) = 0.35386845\n",
      "( king, queen ) = 0.6510956\n",
      "( air, cold ) = 0.23119448\n"
     ]
    }
   ],
   "source": [
    "test_pairs = [\n",
    "    ('computer', 'technology'),\n",
    "    ('king', 'queen'),\n",
    "    ('air', 'cold')\n",
    "]\n",
    "\n",
    "for word1, word2 in test_pairs:\n",
    "  print(\"( \" + word1 + \", \" + word2 + \" ) = \" + str(word2vec.similarity(word1, word2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Cu-6dKEadIE"
   },
   "source": [
    "<b> Create our own Word2Vec model on the words in our corpus and check for semantic similarities of the same 3 paris as above. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QWBUlTShaI2K"
   },
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize\n",
    "from nltk import word_tokenize\n",
    "\n",
    "reviews_text = [word_tokenize(sentence) for sentence in df['review_body'].apply(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "G5EqmINfboYp",
    "outputId": "50d8162b-584f-44f7-e84e-94124b73d6bb"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences = reviews_text, vector_size = 300, window=13, min_count=9)\n",
    "\n",
    "model.save('word2vecmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kLGV-gcbcvMS"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('word2vecmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSrtsB6OdbZB",
    "outputId": "53ca51f4-4b71-4ab8-c648-483f4945df06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( computer, technology ) = 0.2567897\n",
      "( king, queen ) = 0.38569945\n",
      "( air, cold ) = 0.63204056\n"
     ]
    }
   ],
   "source": [
    "for word1, word2 in test_pairs:\n",
    "  print(\"( \" + word1 + \", \" + word2 + \" ) = \" + str(model.wv.similarity(word1, word2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "### What do you conclude from comparing vectors generated by yourself and the pretrained model? \n",
    "\n",
    "Conclusion: The vectors generted by our own model are less accurate as compared to the ones by the pretrained model. This is because the pretrained model has a corpus of all the words in the english language, while our model has only been trained on only the words in our dataset. \\\n",
    "The vectors that are generated by our own Word2Vec model are curated towards the dataset as it is purely trained upon it. The vectors used by the pretrained Google Word2Vec model provide vectors and therefore meanings in a more general domain.\n",
    "\n",
    "\n",
    "\n",
    "### Which of the Word2Vec models seems to encode semantic similarities between words better?\n",
    "\n",
    "The google pretrained model seems to encode semantic similarities better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZK8QfN4TLKH"
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LJ-1a-Xqdr49"
   },
   "outputs": [],
   "source": [
    "reviews = df['review_body']\n",
    "label = df['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOYjYhRHMShP",
    "outputId": "69ba95f7-e70e-48a6-973f-4391f529c830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000 48000 12000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, label, test_size = 0.2, random_state = 2)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm9YeTG5TEOe"
   },
   "source": [
    "## 3. Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Generate word embeddings and find the average value for each sentence based on Word2Vec and TfIdf. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wdlWO6f6MShP"
   },
   "outputs": [],
   "source": [
    "def word_embeddings(review, mod):\n",
    "    doc = np.zeros(300)\n",
    "    n = 0\n",
    "    i = 0\n",
    "    for i in range(len(review)):\n",
    "      if review[i] in mod:\n",
    "        #print(review[i])\n",
    "        doc += mod[review[i]]\n",
    "        n += 1\n",
    "      \n",
    "    if n > 0:\n",
    "      return doc/n\n",
    "    else:\n",
    "      return doc\n",
    "    \n",
    "Xtrain_w2v = []\n",
    "Xtest_w2v = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "SyKpIqCL50So",
    "outputId": "ef6ce30b-5f43-46a9-8fb5-d09201221de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "for rev in X_train:\n",
    "    Xtrain_w2v.append(word_embeddings(rev.split(), word2vec))\n",
    "    \n",
    "for rev in X_test:\n",
    "    Xtest_w2v.append(word_embeddings(rev.split(), word2vec))\n",
    "\n",
    "print(len(Xtrain_w2v), len(Xtest_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XVvLaC6MShP",
    "outputId": "1bff1252-fa06-4a08-9d64-afebd78bf3e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 541283) (12000, 541283)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "Xtrain_tfidf = vectorizer.fit_transform(X_train)\n",
    "Xtest_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(Xtrain_tfidf.shape, Xtest_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gx6HIbiZMShP",
    "outputId": "0dfe35c3-b350-4e36-b9a2-d04c6007cb4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n"
     ]
    }
   ],
   "source": [
    "ytrain = y_train.values\n",
    "ytest = y_test.values\n",
    "\n",
    "print(len(ytrain), len(ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Model\n",
    "\n",
    "<b> Now train a perceptron model for both, the word2vec features and the tfidf features. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_ZRYNZsMShP",
    "outputId": "93be3e51-2a13-436a-8549-eb2ea4403564"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron(random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron_tfidf = Perceptron(random_state = 42)\n",
    "perceptron_tfidf.fit(Xtrain_tfidf, ytrain)\n",
    "\n",
    "perceptron_w2v = Perceptron(random_state = 42)\n",
    "perceptron_w2v.fit(Xtrain_w2v, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "X1dJK7NAMShP"
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "ytest_tfidf_pred_perceptron = perceptron_tfidf.predict(Xtest_tfidf)\n",
    "ytest_w2v_pred_perceptron = perceptron_w2v.predict(Xtest_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Based on the models created, we can make predictions for the testing-data and print the accuracies. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJ7-dg0wMShP",
    "outputId": "aa4433a4-a237-4d46-cc2d-573c1965345f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Model:\n",
      "Accuracy on Tfidf:  0.70125\n",
      "Accuracy on Word2Vec:  0.6244166666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Perceptron Model:\")\n",
    "print(\"Accuracy on Tfidf: \", accuracy_score(ytest, ytest_tfidf_pred_perceptron))\n",
    "print(\"Accuracy on Word2Vec: \", accuracy_score(ytest, ytest_w2v_pred_perceptron))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model \n",
    "\n",
    "<b> Similarly, we train an SVM Model for both, the Word2vec features and tfidf features and print their accuracies on the testing-data. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDFtstbaMShP",
    "outputId": "1f68a070-ee62-4ed7-b884-849a8b3181fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Model:\n",
      "Accuracy on Tfidf:  0.7316666666666667\n",
      "Accuracy on Word2Vec:  0.6636666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_tfidf = LinearSVC(random_state = 2)\n",
    "svm_w2v = LinearSVC(random_state= 2)\n",
    "\n",
    "svm_tfidf.fit(Xtrain_tfidf, ytrain)\n",
    "svm_w2v.fit(Xtrain_w2v, ytrain)\n",
    "\n",
    "ytest_tfidf_pred_svm = svm_tfidf.predict(Xtest_tfidf)\n",
    "ytest_w2v_pred_svm = svm_w2v.predict(Xtest_w2v)\n",
    "\n",
    "print(\"Perceptron Model:\")\n",
    "print(\"Accuracy on Tfidf: \", accuracy_score(ytest, ytest_tfidf_pred_svm))\n",
    "print(\"Accuracy on Word2Vec: \", accuracy_score(ytest, ytest_w2v_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "### What do you conclude from comparing performances for the models trained using the two different feature types (TF-IDF and your trained Word2Vec features)?\n",
    "\n",
    "The performance of the model using TF-IDF features is found to be better as compared to the pretrained model trained using Word2Vec features for both Perceptron as well as SVM. One reason fro this can be that the word embedding method contains a much more ‘noisy’ signal compared to TF-IDF since it is a much more complex word representation and carries much more hidden information. In our case, most of that information is unnecessary and might create false patterns in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kunXOMwdixPs"
   },
   "source": [
    "## 4. Feedforward Neural Networks\n",
    "\n",
    "\n",
    "### Part A: FNN by calculating mean of all Word2Vec vectors for a review\n",
    "\n",
    " <b> Now we use use tensorflow to generate a feedforward neural network containing 2 hidden layers (100 and 10 nodes each) and train it for our data. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "LBg5OHmyI0IF"
   },
   "outputs": [],
   "source": [
    "train_y = ytrain - 1\n",
    "test_y = ytest - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "a9UbbwtZmiTU"
   },
   "outputs": [],
   "source": [
    "Ytest = np.eye(3)[test_y]\n",
    "Ytrain = np.eye(3)[train_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4aZy4FSQiv_c",
    "outputId": "3b085e4f-9018-4fa1-db10-8c3e15aa00ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,143\n",
      "Trainable params: 31,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:18:02.331141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "fnn_model = keras.Sequential()\n",
    "fnn_model.add(keras.layers.InputLayer(input_shape = (300,)))\n",
    "fnn_model.add(keras.layers.Dense(units = 100, activation = tf.nn.leaky_relu))\n",
    "fnn_model.add(keras.layers.Dense(units = 10, activation = tf.nn.leaky_relu))\n",
    "fnn_model.add(keras.layers.Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate = 0.005)\n",
    "fnn_model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "input_shape = (300,)\n",
    "\n",
    "fnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqIwzoWOj8u7",
    "outputId": "3adfdf97-1960-441c-a0ff-e8bad4c9392e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 3s 1ms/step - loss: 0.8245 - accuracy: 0.6221 - val_loss: 0.7747 - val_accuracy: 0.6545\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.7803 - accuracy: 0.6485 - val_loss: 0.7540 - val_accuracy: 0.6674\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 1s 949us/step - loss: 0.7690 - accuracy: 0.6553 - val_loss: 0.7844 - val_accuracy: 0.6446\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 1s 935us/step - loss: 0.7567 - accuracy: 0.6603 - val_loss: 0.7483 - val_accuracy: 0.6695\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 1s 954us/step - loss: 0.7479 - accuracy: 0.6650 - val_loss: 0.7504 - val_accuracy: 0.6701\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 1s 940us/step - loss: 0.7389 - accuracy: 0.6700 - val_loss: 0.7374 - val_accuracy: 0.6748\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 1s 944us/step - loss: 0.7326 - accuracy: 0.6720 - val_loss: 0.7462 - val_accuracy: 0.6736\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 1s 991us/step - loss: 0.7272 - accuracy: 0.6755 - val_loss: 0.7420 - val_accuracy: 0.6727\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 1s 991us/step - loss: 0.7220 - accuracy: 0.6799 - val_loss: 0.7503 - val_accuracy: 0.6657\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.7152 - accuracy: 0.6803 - val_loss: 0.7977 - val_accuracy: 0.6461\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.7118 - accuracy: 0.6843 - val_loss: 0.7541 - val_accuracy: 0.6676\n"
     ]
    }
   ],
   "source": [
    "Xtest_w2v = np.array(Xtest_w2v)\n",
    "Xtrain_w2v = np.array(Xtrain_w2v)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = fnn_model.fit(Xtrain_w2v, \n",
    "                        Ytrain, \n",
    "                        epochs = 50, \n",
    "                        validation_data=(Xtest_w2v, Ytest), \n",
    "                        callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IDIfU7znXYu",
    "outputId": "50f2d215-4b26-464d-9d2d-d7085f50a6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 559us/step\n"
     ]
    }
   ],
   "source": [
    "ypred_fnn = fnn_model.predict(Xtest_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Generate the accuracy for testing data for word2vec model. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8X3IWs2WCx_",
    "outputId": "f8b0733b-4c22-4325-cd98-26077a7456c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data for feedforward neural network:\n",
      "Accuracy on Word2Vec:  0.6748333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Ypred_fnn = np.argmax(ypred_fnn, axis=1)\n",
    "print(\"Accuracy on testing data for feedforward neural network:\")\n",
    "print(\"Accuracy on Word2Vec: \", accuracy_score(test_y, Ypred_fnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFiThIbBrMR4"
   },
   "source": [
    "### Part B: FNN by concatenating the first 10 Word2Vec vectors for each review\n",
    "\n",
    " <b> We train the same FNN model by changing the training data to include the first 10 vectors instead of using mean values. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first10(model, words):\n",
    "    word = []\n",
    "    count = 0\n",
    "    for i in words.split():\n",
    "        if i in model:\n",
    "            word.append(model[i])\n",
    "            count += 1\n",
    "            if count ==10:\n",
    "                break\n",
    "    \n",
    "    while count!= 10:\n",
    "        word.append(np.zeros(300))\n",
    "        count += 1\n",
    "    \n",
    "    return np.reshape(word, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.array(X_train)\n",
    "Xtrain_fnn_10 = [first10(word2vec, vec) for vec in X_train]\n",
    "\n",
    "Xtest = np.array(X_test)\n",
    "Xtest_fnn_10 = [first10(word2vec, vec) for vec in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3DG4Mog8Sete"
   },
   "outputs": [],
   "source": [
    "ytrain = y_train.values - 1\n",
    "ytest = y_test.values - 1\n",
    "\n",
    "Ytrain = np.zeros((len(ytrain), 3))\n",
    "for i, prediction in enumerate(ytrain):\n",
    "    Ytrain[i, prediction] = 1\n",
    "\n",
    "Ytest = np.zeros((len(ytest), 3))\n",
    "for i, prediction in enumerate(ytest):\n",
    "    Ytest[i, prediction] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UF-wRn6RTFXX",
    "outputId": "79038fda-2f52-4106-ea96-11a1e43ec8d9"
   },
   "outputs": [],
   "source": [
    "Xtrain_fnn_10 = np.array(Xtrain_fnn_10)\n",
    "Xtest_fnn_10 = np.array(Xtest_fnn_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbyaqyiWtXxm",
    "outputId": "97c1ac5a-4f14-4aa9-bf87-4c8c54b02dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               300100    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301,143\n",
      "Trainable params: 301,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "fnn10_model = keras.Sequential()\n",
    "fnn10_model.add(keras.layers.InputLayer(input_shape = (3000,)))\n",
    "fnn10_model.add(keras.layers.Dense(units = 100, activation = 'relu'))\n",
    "fnn10_model.add(keras.layers.Dropout(0.3))\n",
    "fnn10_model.add(keras.layers.Dense(units = 10, activation = 'relu'))\n",
    "fnn10_model.add(keras.layers.Dropout(0.3))\n",
    "fnn10_model.add(keras.layers.Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate = 0.0005)\n",
    "fnn10_model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "fnn10_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "qtAX_msetoDn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.9815 - accuracy: 0.4983 - val_loss: 0.9091 - val_accuracy: 0.5753\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.9092 - accuracy: 0.5590 - val_loss: 0.8810 - val_accuracy: 0.5848\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.8752 - accuracy: 0.5800 - val_loss: 0.8805 - val_accuracy: 0.5807\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.8390 - accuracy: 0.6049 - val_loss: 0.8772 - val_accuracy: 0.5877\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.8064 - accuracy: 0.6256 - val_loss: 0.8844 - val_accuracy: 0.5857\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7698 - accuracy: 0.6472 - val_loss: 0.8917 - val_accuracy: 0.5846\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7317 - accuracy: 0.6695 - val_loss: 0.9135 - val_accuracy: 0.5734\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6947 - accuracy: 0.6940 - val_loss: 0.9234 - val_accuracy: 0.5667\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6585 - accuracy: 0.7102 - val_loss: 0.9554 - val_accuracy: 0.5714\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6280 - accuracy: 0.7268 - val_loss: 0.9815 - val_accuracy: 0.5676\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5972 - accuracy: 0.7412 - val_loss: 1.0185 - val_accuracy: 0.5626\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5646 - accuracy: 0.7578 - val_loss: 1.0506 - val_accuracy: 0.5593\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5402 - accuracy: 0.7720 - val_loss: 1.0892 - val_accuracy: 0.5623\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5204 - accuracy: 0.7812 - val_loss: 1.1212 - val_accuracy: 0.5592\n"
     ]
    }
   ],
   "source": [
    "Xtest_fnn_10 = np.array(Xtest_fnn_10)\n",
    "Xtrain_fnn_10 = np.array(Xtrain_fnn_10)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = fnn10_model.fit(Xtrain_fnn_10, Ytrain, epochs = 50, validation_data=(Xtest_fnn_10, Ytest), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "IO_oKTuDtvxF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 684us/step\n"
     ]
    }
   ],
   "source": [
    "ypred_fnn_10 = fnn10_model.predict(Xtest_fnn_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Generate the accuracy for testing data for word2vec model. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "X9lLU-BgwLK9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data for feedforward neural network:\n",
      "Accuracy on Word2Vec:  0.5876666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Ypred_fnn_10 = np.argmax(ypred_fnn_10, axis=1)\n",
    "print(\"Accuracy on testing data for feedforward neural network:\")\n",
    "print(\"Accuracy on Word2Vec: \", accuracy_score(ytest, Ypred_fnn_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "### What do you conclude by comparing accuracy values you obtain with those obtained in the “’Simple Models” section?\n",
    "\n",
    "The accuracy values of FNN for Word2Vec are slightly better than that of SVM for Word2Vec features. The accuracy for the first 10 Word2Vec vectors for feedforward neural network is around the range of Perceptron accuracy, which is slightly lower than the FNN trained on the mean values of the vector. This is because the first 10 words in a review sometimes might not have a lot of context and meaning to them; thus not being very helpful for categorization.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recurrent Neural Networks\n",
    "\n",
    "<b> Now we implement 3 types of RNN, and comapre their performance on the word2vec vectors for our dataset. We are cosidering an RNN cell with the hidden state size of 20, which means we need to truncate each review to a size of 20 words, and if any review has length less than 20, we add padding of the remaining size. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "yDfSiPn5wSH8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "Xtrain_w2v_rnn = []\n",
    "Xtest_w2v_rnn  = []\n",
    "\n",
    "for sentence in X_train:\n",
    "\n",
    "    sentence_vectors = []\n",
    "    sent = sentence.split()\n",
    "\n",
    "    for word in sent:\n",
    "        if word in word2vec:\n",
    "            word_vectors = word2vec[word]\n",
    "\n",
    "        sentence_vectors.append(word_vectors)\n",
    "\n",
    "    Xtrain_w2v_rnn.append(sentence_vectors)\n",
    "        \n",
    "        \n",
    "for sentence in X_test:\n",
    "    sentence_vectors = []\n",
    "    sent = sentence.split()\n",
    "    for word in sent:\n",
    "        if word in word2vec:\n",
    "            word_vectors = word2vec[word]\n",
    "\n",
    "        sentence_vectors.append(word_vectors)\n",
    "\n",
    "    Xtest_w2v_rnn.append(sentence_vectors)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_review_length = 20\n",
    "\n",
    "Xtrain_rnn = pad_sequences(Xtrain_w2v_rnn, maxlen=max_review_length, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "Xtest_rnn = pad_sequences(Xtest_w2v_rnn, maxlen=max_review_length, dtype='float32', padding='post', truncating='post', value=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = len(word2vec.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Simple RNN\n",
    "\n",
    "<b> We train a simple RNN with one masking layer and one SImpleRNN layer with hidden state size of 20. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "rnn_model = keras.Sequential()\n",
    "#rnn_model.add(keras.layers.Embedding(input_dim = input_dimension, output_dim=300, input_length = 20, trainable = False))\n",
    "rnn_model.add(keras.layers.Masking())\n",
    "rnn_model.add(keras.layers.SimpleRNN(units=20, activation='relu'))\n",
    "rnn_model.add(keras.layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate = 0.001)\n",
    "rnn_model.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "\n",
    "#print(rnn_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:19:04.895077: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-03-01 11:19:04.942639: W tensorflow/c/c_api.cc:291] Operation '{name:'training/Adam/sequential_2/simple_rnn/simple_rnn_cell/bias/v/Assign' id:519 op device:{requested: '', assigned: ''} def:{{{node training/Adam/sequential_2/simple_rnn/simple_rnn_cell/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/sequential_2/simple_rnn/simple_rnn_cell/bias/v, training/Adam/sequential_2/simple_rnn/simple_rnn_cell/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47616/48000 [============================>.] - ETA: 0s - loss: 0.9724 - accuracy: 0.5014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:19:10.145966: W tensorflow/c/c_api.cc:291] Operation '{name:'loss/mul' id:335 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/output_1_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.9725 - accuracy: 0.5016 - val_loss: 0.9054 - val_accuracy: 0.5570\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.8896 - accuracy: 0.5751 - val_loss: 0.8708 - val_accuracy: 0.5839\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.8604 - accuracy: 0.5949 - val_loss: 0.8706 - val_accuracy: 0.5847\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.8446 - accuracy: 0.6042 - val_loss: 0.8410 - val_accuracy: 0.6022\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.8280 - accuracy: 0.6181 - val_loss: 0.8427 - val_accuracy: 0.6047\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.8179 - accuracy: 0.6251 - val_loss: 0.8271 - val_accuracy: 0.6102\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.8095 - accuracy: 0.6300 - val_loss: 0.8258 - val_accuracy: 0.6160\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 0.8009 - accuracy: 0.6345 - val_loss: 0.8192 - val_accuracy: 0.6188\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.7923 - accuracy: 0.6411 - val_loss: 0.8258 - val_accuracy: 0.6118\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.7863 - accuracy: 0.6416 - val_loss: 0.8202 - val_accuracy: 0.6165\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.7816 - accuracy: 0.6454 - val_loss: 0.8199 - val_accuracy: 0.6170\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.7748 - accuracy: 0.6502 - val_loss: 0.8176 - val_accuracy: 0.6159\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.7696 - accuracy: 0.6545 - val_loss: 0.8122 - val_accuracy: 0.6237\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.7654 - accuracy: 0.6555 - val_loss: 0.8365 - val_accuracy: 0.6087\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.7627 - accuracy: 0.6591 - val_loss: 0.8222 - val_accuracy: 0.6219\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.7591 - accuracy: 0.6597 - val_loss: 0.8338 - val_accuracy: 0.6158\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.7554 - accuracy: 0.6619 - val_loss: 0.8568 - val_accuracy: 0.6132\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.7521 - accuracy: 0.6659 - val_loss: 0.8188 - val_accuracy: 0.6232\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.7500 - accuracy: 0.6666 - val_loss: 0.8224 - val_accuracy: 0.6202\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.7476 - accuracy: 0.6665 - val_loss: 0.8150 - val_accuracy: 0.6264\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.7451 - accuracy: 0.6665 - val_loss: 0.8168 - val_accuracy: 0.6308\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.7402 - accuracy: 0.6702 - val_loss: 0.8082 - val_accuracy: 0.6317\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.7397 - accuracy: 0.6722 - val_loss: 0.8200 - val_accuracy: 0.6214\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.7373 - accuracy: 0.6701 - val_loss: 0.8846 - val_accuracy: 0.6083\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.7349 - accuracy: 0.6746 - val_loss: 0.8224 - val_accuracy: 0.6259\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.7323 - accuracy: 0.6772 - val_loss: 0.8257 - val_accuracy: 0.6286\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.7301 - accuracy: 0.6754 - val_loss: 0.8170 - val_accuracy: 0.6346\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.7279 - accuracy: 0.6779 - val_loss: 0.8540 - val_accuracy: 0.6222\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.7252 - accuracy: 0.6790 - val_loss: 0.8232 - val_accuracy: 0.6308\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.7244 - accuracy: 0.6788 - val_loss: 0.8406 - val_accuracy: 0.6248\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.7228 - accuracy: 0.6812 - val_loss: 0.8172 - val_accuracy: 0.6302\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.7205 - accuracy: 0.6809 - val_loss: 0.8175 - val_accuracy: 0.6337\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.7188 - accuracy: 0.6829 - val_loss: 0.8224 - val_accuracy: 0.6240\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.7174 - accuracy: 0.6836 - val_loss: 0.8250 - val_accuracy: 0.6280\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 97s 2ms/sample - loss: 0.7163 - accuracy: 0.6829 - val_loss: 0.8224 - val_accuracy: 0.6253\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.7137 - accuracy: 0.6847 - val_loss: 0.8245 - val_accuracy: 0.6297\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.7140 - accuracy: 0.6847 - val_loss: 0.8434 - val_accuracy: 0.6314\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.7133 - accuracy: 0.6859 - val_loss: 0.8602 - val_accuracy: 0.6266\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.7118 - accuracy: 0.6847 - val_loss: 0.8287 - val_accuracy: 0.6246\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.7107 - accuracy: 0.6857 - val_loss: 0.8278 - val_accuracy: 0.6285\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.7103 - accuracy: 0.6876 - val_loss: 0.8243 - val_accuracy: 0.6210\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.7075 - accuracy: 0.6883 - val_loss: 0.8430 - val_accuracy: 0.6194\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.7064 - accuracy: 0.6882 - val_loss: 0.8551 - val_accuracy: 0.6203\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.7058 - accuracy: 0.6899 - val_loss: 0.8444 - val_accuracy: 0.6302\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.7043 - accuracy: 0.6894 - val_loss: 0.8484 - val_accuracy: 0.6245\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.7037 - accuracy: 0.6910 - val_loss: 0.8348 - val_accuracy: 0.6209\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.7041 - accuracy: 0.6906 - val_loss: 0.8432 - val_accuracy: 0.6316\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.7012 - accuracy: 0.6930 - val_loss: 0.8513 - val_accuracy: 0.6288\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.7017 - accuracy: 0.6927 - val_loss: 0.8314 - val_accuracy: 0.6273\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.7011 - accuracy: 0.6917 - val_loss: 0.8311 - val_accuracy: 0.6288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2488a0040>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3, restore_best_weights=True)\n",
    "rnn_model.fit(Xtrain_rnn, Ytrain, epochs=50, validation_data=(Xtest_rnn, Ytest), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:25:03.238749: W tensorflow/c/c_api.cc:291] Operation '{name:'sequential_2/dense_6/Softmax' id:259 op device:{requested: '', assigned: ''} def:{{{node sequential_2/dense_6/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](sequential_2/dense_6/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "ypred_rnn = rnn_model.predict(Xtest_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Generate the accuracy for testing data for word2vec model. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data for recurrent neural network:\n",
      "Accuracy on Word2Vec:  0.62875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Ypred_rnn = np.argmax(ypred_rnn, axis=1)\n",
    "print(\"Accuracy on testing data for recurrent neural network:\")\n",
    "print(\"Accuracy on Word2Vec: \", accuracy_score(ytest, Ypred_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "### What do you conclude by comparing accuracy values you obtain with those obtained with feedforward neural network models? \n",
    "\n",
    "The accuracy values for FNN and RNN are very similar, and can vary a little based on hyperparameter tuning, number of epochs and activation used on each layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 GRU (Gated Recurrent Unit):\n",
    "\n",
    "<b> We train a GRU model with one masking layer and one GRU layer with hidden state size of 20. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "gru_model = keras.Sequential()\n",
    "#rnn_model.add(keras.layers.Embedding(input_dim = input_dimension, output_dim=300, input_length = 20, trainable = False))\n",
    "gru_model.add(keras.layers.Masking())\n",
    "gru_model.add(keras.layers.GRU(units=20, activation='relu'))\n",
    "gru_model.add(keras.layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate = 0.001)\n",
    "gru_model.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "\n",
    "#print(rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:25:04.215237: W tensorflow/c/c_api.cc:291] Operation '{name:'total_1/Assign' id:969 op device:{requested: '', assigned: ''} def:{{{node total_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](total_1, total_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47968/48000 [============================>.] - ETA: 0s - loss: 0.8931 - accuracy: 0.5702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:25:12.288229: W tensorflow/c/c_api.cc:291] Operation '{name:'loss_1/mul' id:1040 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/output_1_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 9s 182us/sample - loss: 0.8930 - accuracy: 0.5703 - val_loss: 0.8244 - val_accuracy: 0.6221\n",
      "Epoch 2/15\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.8063 - accuracy: 0.6306 - val_loss: 0.7936 - val_accuracy: 0.6368\n",
      "Epoch 3/15\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.7805 - accuracy: 0.6458 - val_loss: 0.7714 - val_accuracy: 0.6528\n",
      "Epoch 4/15\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.7602 - accuracy: 0.6554 - val_loss: 0.7632 - val_accuracy: 0.6567\n",
      "Epoch 5/15\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.7454 - accuracy: 0.6624 - val_loss: 0.7556 - val_accuracy: 0.6600\n",
      "Epoch 6/15\n",
      "48000/48000 [==============================] - 9s 180us/sample - loss: 0.7320 - accuracy: 0.6713 - val_loss: 0.7502 - val_accuracy: 0.6626\n",
      "Epoch 7/15\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.7207 - accuracy: 0.6762 - val_loss: 0.7490 - val_accuracy: 0.6645\n",
      "Epoch 8/15\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.7106 - accuracy: 0.6816 - val_loss: 0.7481 - val_accuracy: 0.6622\n",
      "Epoch 9/15\n",
      "48000/48000 [==============================] - 9s 188us/sample - loss: 0.7028 - accuracy: 0.6835 - val_loss: 0.7557 - val_accuracy: 0.6595\n",
      "Epoch 10/15\n",
      "48000/48000 [==============================] - 9s 181us/sample - loss: 0.6965 - accuracy: 0.6870 - val_loss: 0.7487 - val_accuracy: 0.6639\n",
      "Epoch 11/15\n",
      "48000/48000 [==============================] - 9s 184us/sample - loss: 0.6887 - accuracy: 0.6924 - val_loss: 0.7490 - val_accuracy: 0.6597\n",
      "Epoch 12/15\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.6819 - accuracy: 0.6954 - val_loss: 0.7540 - val_accuracy: 0.6587\n",
      "Epoch 13/15\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.6757 - accuracy: 0.7000 - val_loss: 0.7546 - val_accuracy: 0.6616\n",
      "Epoch 14/15\n",
      "48000/48000 [==============================] - 9s 189us/sample - loss: 0.6701 - accuracy: 0.7017 - val_loss: 0.7594 - val_accuracy: 0.6637\n",
      "Epoch 15/15\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.6631 - accuracy: 0.7048 - val_loss: 0.7640 - val_accuracy: 0.6578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a32bf40>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3, restore_best_weights=True)\n",
    "gru_model.fit(Xtrain_rnn, Ytrain, epochs=15 , validation_data=(Xtest_rnn, Ytest), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:27:15.492140: W tensorflow/c/c_api.cc:291] Operation '{name:'sequential_3/dense_7/Softmax' id:964 op device:{requested: '', assigned: ''} def:{{{node sequential_3/dense_7/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](sequential_3/dense_7/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "ypred_gru = gru_model.predict(Xtest_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Generate the accuracy for testing data for word2vec model. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data for GRU neural network:\n",
      "Accuracy on Word2Vec:  0.6578333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Ypred_gru = np.argmax(ypred_gru, axis=1)\n",
    "print(\"Accuracy on testing data for GRU neural network:\")\n",
    "print(\"Accuracy on Word2Vec: \", accuracy_score(ytest, Ypred_gru))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 LSTM network:\n",
    "\n",
    "<b> We train an LSTM model with one masking layer and one LSTM layer with hidden state size of 20. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "lstm_model = keras.Sequential()\n",
    "#rnn_model.add(keras.layers.Embedding(input_dim = input_dimension, output_dim=300, input_length = 20, trainable = False))\n",
    "lstm_model.add(keras.layers.Masking())\n",
    "lstm_model.add(keras.layers.LSTM(units=20, activation='relu'))\n",
    "lstm_model.add(keras.layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate = 0.001)\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "\n",
    "#print(rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:27:16.724986: W tensorflow/c/c_api.cc:291] Operation '{name:'training_4/Adam/sequential_4/dense_8/kernel/v/Assign' id:1981 op device:{requested: '', assigned: ''} def:{{{node training_4/Adam/sequential_4/dense_8/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_4/Adam/sequential_4/dense_8/kernel/v, training_4/Adam/sequential_4/dense_8/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47776/48000 [============================>.] - ETA: 0s - loss: 0.8968 - accuracy: 0.5742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:27:26.608582: W tensorflow/c/c_api.cc:291] Operation '{name:'loss_2/mul' id:1761 op device:{requested: '', assigned: ''} def:{{{node loss_2/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_2/mul/x, loss_2/output_1_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 11s 225us/sample - loss: 0.8965 - accuracy: 0.5742 - val_loss: 0.8263 - val_accuracy: 0.6217\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 10s 208us/sample - loss: 0.8060 - accuracy: 0.6300 - val_loss: 0.8013 - val_accuracy: 0.6342\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 11s 236us/sample - loss: 0.7748 - accuracy: 0.6459 - val_loss: 0.7913 - val_accuracy: 0.6366\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 10s 204us/sample - loss: 0.7541 - accuracy: 0.6569 - val_loss: 0.7710 - val_accuracy: 0.6528\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.7365 - accuracy: 0.6677 - val_loss: 0.7660 - val_accuracy: 0.6520\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 11s 224us/sample - loss: 0.7216 - accuracy: 0.6758 - val_loss: 0.7690 - val_accuracy: 0.6498\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 10s 209us/sample - loss: 0.7087 - accuracy: 0.6811 - val_loss: 0.7632 - val_accuracy: 0.6572\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 87s 2ms/sample - loss: 0.6993 - accuracy: 0.6855 - val_loss: 0.7716 - val_accuracy: 0.6464\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 11s 220us/sample - loss: 0.6895 - accuracy: 0.6904 - val_loss: 0.7623 - val_accuracy: 0.6568\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 12s 254us/sample - loss: 0.6792 - accuracy: 0.6952 - val_loss: 0.7682 - val_accuracy: 0.6539\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 10s 218us/sample - loss: 0.6718 - accuracy: 0.6987 - val_loss: 0.7667 - val_accuracy: 0.6572\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 9s 194us/sample - loss: 0.6626 - accuracy: 0.7038 - val_loss: 0.7961 - val_accuracy: 0.6499\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 9s 197us/sample - loss: 0.6557 - accuracy: 0.7074 - val_loss: 0.7831 - val_accuracy: 0.6543\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 10s 203us/sample - loss: 0.6467 - accuracy: 0.7115 - val_loss: 0.7787 - val_accuracy: 0.6526\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 10s 203us/sample - loss: 0.6402 - accuracy: 0.7164 - val_loss: 0.7849 - val_accuracy: 0.6547\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 11s 226us/sample - loss: 0.6327 - accuracy: 0.7200 - val_loss: 0.8069 - val_accuracy: 0.6521\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 10s 206us/sample - loss: 0.6261 - accuracy: 0.7239 - val_loss: 0.7993 - val_accuracy: 0.6519\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 9s 197us/sample - loss: 0.6189 - accuracy: 0.7263 - val_loss: 0.8088 - val_accuracy: 0.6501\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 10s 208us/sample - loss: 0.6139 - accuracy: 0.7281 - val_loss: 0.8099 - val_accuracy: 0.6455\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 10s 207us/sample - loss: 0.6080 - accuracy: 0.7305 - val_loss: 0.8245 - val_accuracy: 0.6486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a56ceb0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3, restore_best_weights=True)\n",
    "lstm_model.fit(Xtrain_rnn, Ytrain, epochs=20, validation_data=(Xtest_rnn, Ytest), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:31:57.632217: W tensorflow/c/c_api.cc:291] Operation '{name:'sequential_4/dense_8/Softmax' id:1685 op device:{requested: '', assigned: ''} def:{{{node sequential_4/dense_8/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](sequential_4/dense_8/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "ypred_lstm = lstm_model.predict(Xtest_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Generate the accuracy for testing data for word2vec model. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data for LSTM neural network:\n",
      "Accuracy on Word2Vec:  0.6485833333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Ypred_lstm = np.argmax(ypred_lstm, axis=1)\n",
    "print(\"Accuracy on testing data for LSTM neural network:\")\n",
    "print(\"Accuracy on Word2Vec: \", accuracy_score(ytest, Ypred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "### What do you conclude by comparing accuracy values you obtain by GRU, LSTM, and simple RNN?\n",
    "\n",
    "GRU and LSTM networks perform well and give very similar accuracies on the testing data. SimpleRNN model does not perform as well because it has a short-term memory problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Package versions for all libraries\n",
    "\n",
    "# import sys\n",
    "# import sklearn as sk\n",
    "# import gensim as gen\n",
    "# print(\"Python\" , sys.version)\n",
    "# print(\"Pandas\" , pd.__version__)\n",
    "# print(\"Numpy \" , np.version.version)\n",
    "# print(\"Scikit-learn\" , sk.__version__)\n",
    "# print(\"NLTK \", nltk.__version__)\n",
    "# print(\"Tensorflow\" , tf.__version__)\n",
    "# print(\"Gensim \" , gen.__version__)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
